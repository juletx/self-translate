{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1WyizOq0r79K444FA-fVqhfgoI5nGilGI","authorship_tag":"ABX9TyM69cPbUhlcMaws6sAOIYSz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Few-shot Learning with Multilingual Language Models (XGLM)"],"metadata":{"id":"8R0eCB_EtG5x"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"id":"K65uPzXVq-Tm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/PhD Julen Etxaniz/phd/datasets/XStoryCloze"],"metadata":{"id":"WcZEYKCKUAK5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Introduction\n","\n","In this work, we train a family of multilingual generative language models, dubbed XGLM, on a balanced corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning on more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (+7.4 accuracy points for 0-shot, +9.4 for 4-shot) and natural language inference (+5.4 for 0-shot, +5.4 for 4-shot). We have included a [model card](model_card.md) of XGLM for transparency and accountability.\n","\n"],"metadata":{"id":"njS2ycS8wu1N"}},{"cell_type":"markdown","source":["## Data and Languages\n","XGLM models are trained on a new multilingual corpus extracted from CommonCrawl (CC100-XL), a significantly larger multilingual dataset covering 68 Common Crawl (CC) snapshots (from [Summer 2013](http://commoncrawl.org/2013/11/new-crawl-data-available/) to [March/April 2020](https://commoncrawl.org/2020/04/march-april-2020-crawl-archive-now-available/) consisting of 134 languages. The detailed languages and data statistics are reported in the paper (Table A.1).\n","\n"],"metadata":{"id":"_kqwe5-gwxnQ"}},{"cell_type":"markdown","source":["## Pre-trained models\n","\n","Model | Layers | Model Dim | FFN Dim | Languages | Download\n","---|---|---|---|---|---\n","`XGLM 564M` | 24 | 1024 | 4096 | trained on 30 languages|  [xglm.564M.tar.gz](https://dl.fbaipublicfiles.com/fairseq/models/xglm/xglm.564M.tar.gz)\n","`XGLM 1.7B` | 24 | 2048 | 8192 | trained on 30 languages|  [xglm.1.7B.tar.gz](https://dl.fbaipublicfiles.com/fairseq/models/xglm/xglm.1.7B.tar.gz)\n","`XGLM 2.9B` | 48 | 2048 | 8192 | trained on 30 languages|  [xglm.2.9B.tar.gz](https://dl.fbaipublicfiles.com/fairseq/models/xglm/xglm.2.9B.tar.gz)\n","`XGLM 7.5B` | 32 | 4096 | 16384 | trained on 30 languages|  [xglm.7.5B.tar.gz](https://dl.fbaipublicfiles.com/fairseq/models/xglm/xglm.7.5B.tar.gz)\n","`XGLM 4.5B` | 48 | 2048 | 16384 | trained on 134 languages|  [xglm.4.5B.tar.gz](https://dl.fbaipublicfiles.com/fairseq/models/xglm/xglm.4.5B.tar.gz)"],"metadata":{"id":"Z0X4Mt19w09E"}},{"cell_type":"markdown","source":["## Evaluation\n","\n"],"metadata":{"id":"_eSAHAQYtcvd"}},{"cell_type":"code","source":["from transformers import XGLMTokenizer, XGLMForCausalLM\n","\n","tokenizer = XGLMTokenizer.from_pretrained(\"facebook/xglm-564M\")\n","model = XGLMForCausalLM.from_pretrained(\"facebook/xglm-564M\")\n","model.eval()\n","model.cuda()"],"metadata":{"id":"fcWXeeVWr1ha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### XCOPA"],"metadata":{"id":"wAgRzE1q3i4h"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","langs_xcopa = [\"et\", \"ht\", \"it\", \"id\", \"qu\", \"sw\", \"zh\", \"ta\", \"th\", \"tr\", \"vi\"]\n","\n","xcopa = {}\n","for lang in langs_xcopa:\n","    xcopa[lang] = load_dataset(\"xcopa\", lang)"],"metadata":{"id":"GoU5gVsA3le5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xcopa[\"et\"][\"validation\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnlYu63CxLmY","executionInfo":{"status":"ok","timestamp":1674647542772,"user_tz":-60,"elapsed":8,"user":{"displayName":"Julen Etxaniz Aragoneses","userId":"06956422670240182492"}},"outputId":"cbf1b95c-ebf2-4ff7-d303-7a11d89bd7ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'premise': 'Mees keeras kraani lahti.',\n"," 'choice1': 'Tualett täitus veega.',\n"," 'choice2': 'Tilast voolas vett.',\n"," 'question': 'effect',\n"," 'label': 1,\n"," 'idx': 0,\n"," 'changed': False}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import pandas as pd\n","\n","def get_logprobs(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    input_ids, output_ids = inputs[\"input_ids\"], inputs[\"input_ids\"][:, 1:]\n","    outputs = model(**inputs, labels=input_ids)\n","    logits = outputs.logits\n","    logprobs = torch.gather(F.log_softmax(logits, dim=2), 2, output_ids.unsqueeze(2))\n","    return logprobs\n","\n","# Zero-shot evaluation for the Choice of Plausible Alternatives (COPA) task.\n","# A return value of 0 indicates that the first alternative is more plausible,\n","# while 1 indicates that the second alternative is more plausible.\n","def XCOPA_eval(prompt, alternative1, alternative2):\n","    lprob1 = get_logprobs(prompt + \"\\n\" + alternative1).sum()\n","    lprob2 = get_logprobs(prompt + \"\\n\" + alternative2).sum()\n","    return 0 if lprob1 > lprob2 else 1\n","\n","results_xcopa = {\"idx\": xcopa[\"et\"][\"test\"][\"idx\"], \n","           \"label\": xcopa[\"et\"][\"test\"][\"label\"]}\n","for lang in langs_xcopa:\n","    predictions = []\n","    for idx, example in tqdm(enumerate(xcopa[lang][\"test\"])):\n","        predict = XCOPA_eval(example[\"premise\"], example[\"choice1\"], example[\"choice2\"])\n","        predictions.append(predict)\n","    results_xcopa[lang] = predictions"],"metadata":{"id":"DlX9gOLB4ADG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674658173557,"user_tz":-60,"elapsed":567788,"user":{"displayName":"Julen Etxaniz Aragoneses","userId":"06956422670240182492"}},"outputId":"75b1b17e-13e3-4f2b-978c-86e992d276a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["500it [00:54,  9.15it/s]\n","500it [00:50,  9.83it/s]\n","500it [00:50,  9.84it/s]\n","500it [00:50,  9.95it/s]\n","500it [00:51,  9.74it/s]\n","500it [00:50,  9.82it/s]\n","500it [00:50,  9.82it/s]\n","500it [00:55,  9.01it/s]\n","500it [00:50,  9.89it/s]\n","500it [00:50,  9.84it/s]\n","500it [00:50,  9.84it/s]\n"]}]},{"cell_type":"code","source":["results_xcopa_df = pd.DataFrame(results_xcopa).to_csv(\"XCOPA_xglm-564M.tsv\", sep=\"\\t\", index=False)"],"metadata":{"id":"WvaedcsIWhpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_xcopa_df = pd.read_csv(\"XCOPA_xglm-564M.tsv\", delimiter=\"\\t\")"],"metadata":{"id":"C3IHth8GWhpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_xcopa_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1674658173565,"user_tz":-60,"elapsed":43,"user":{"displayName":"Julen Etxaniz Aragoneses","userId":"06956422670240182492"}},"outputId":"146f7ed8-43ae-4872-f47e-fb66504fd870","id":"jVGC3FJPWhpo"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     idx  label  et  ht  it  id  qu  sw  zh  ta  th  tr  vi\n","0      0      0   1   1   1   1   1   1   1   1   1   1   1\n","1      1      0   1   1   1   1   1   1   1   1   1   1   1\n","2      2      1   0   0   0   1   0   0   0   0   1   0   0\n","3      3      0   0   0   0   0   0   0   0   0   0   0   0\n","4      4      0   1   0   1   0   0   0   1   0   1   1   1\n","..   ...    ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n","495  495      1   1   1   1   1   1   0   0   0   1   1   1\n","496  496      1   0   0   0   0   0   0   1   0   0   0   1\n","497  497      0   0   1   0   0   0   1   1   0   1   1   0\n","498  498      1   0   1   1   1   1   0   1   1   1   0   1\n","499  499      1   1   1   0   0   0   1   1   1   0   0   0\n","\n","[500 rows x 13 columns]"],"text/html":["\n","  <div id=\"df-cc6f1022-8e90-403b-ab28-2c69df942fa7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>label</th>\n","      <th>et</th>\n","      <th>ht</th>\n","      <th>it</th>\n","      <th>id</th>\n","      <th>qu</th>\n","      <th>sw</th>\n","      <th>zh</th>\n","      <th>ta</th>\n","      <th>th</th>\n","      <th>tr</th>\n","      <th>vi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 13 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc6f1022-8e90-403b-ab28-2c69df942fa7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc6f1022-8e90-403b-ab28-2c69df942fa7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc6f1022-8e90-403b-ab28-2c69df942fa7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["accuracy = {}\n","for lang in langs_xcopa:\n","    compare = results_xcopa_df[\"label\"] == results_xcopa_df[lang]\n","    acc = list(compare).count(True) / len(list(compare)) * 100\n","    accuracy[lang] = round(acc, 2)\n","\n","accuracy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U56_3nEaW_Ay","executionInfo":{"status":"ok","timestamp":1674658390240,"user_tz":-60,"elapsed":11,"user":{"displayName":"Julen Etxaniz Aragoneses","userId":"06956422670240182492"}},"outputId":"efe9156c-f650-4896-ac16-e3522f8f99f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'et': 52.4,\n"," 'ht': 54.2,\n"," 'it': 52.0,\n"," 'id': 55.8,\n"," 'qu': 49.2,\n"," 'sw': 52.8,\n"," 'zh': 53.2,\n"," 'ta': 54.4,\n"," 'th': 55.6,\n"," 'tr': 53.0,\n"," 'vi': 55.8}"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["### XStoryCloze"],"metadata":{"id":"qC0JButVykCt"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","langs_xstory = [\"en\", \"ru\", \"zh\", \"es\", \"ar\", \"hi\", \"id\", \"te\", \"sw\", \"eu\", \"my\"]\n","\n","x_story_cloze = {}\n","for lang in langs_xstory:\n","    x_story_cloze[lang] = load_dataset('x_story_cloze.py', lang)"],"metadata":{"id":"0AnmZM46zTVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_story_cloze[\"en\"][\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUOi57qRxGUy","executionInfo":{"status":"ok","timestamp":1674647479344,"user_tz":-60,"elapsed":13,"user":{"displayName":"Julen Etxaniz Aragoneses","userId":"06956422670240182492"}},"outputId":"fdd456be-6b21-4db7-89f5-66019a38643a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'story_id': '138d5bfb-05cc-41e3-bf2c-fa85ebad14e2',\n"," 'input_sentence_1': 'Rick grew up in a troubled household.',\n"," 'input_sentence_2': 'He never found good support in family, and turned to gangs.',\n"," 'input_sentence_3': \"It wasn't long before Rick got shot in a robbery.\",\n"," 'input_sentence_4': 'The incident caused him to turn a new leaf.',\n"," 'sentence_quiz1': 'He is happy now.',\n"," 'sentence_quiz2': 'He joined a gang.',\n"," 'answer_right_ending': 1}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import pandas as pd\n","\n","def get_logprobs(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    input_ids, output_ids = inputs[\"input_ids\"], inputs[\"input_ids\"][:, 1:]\n","    outputs = model(**inputs, labels=input_ids)\n","    logits = outputs.logits\n","    logprobs = torch.gather(F.log_softmax(logits, dim=2), 2, output_ids.unsqueeze(2))\n","    return logprobs\n","\n","def XStoryCloze_eval(prompt, alternative1, alternative2):\n","    lprob1 = get_logprobs(prompt + \"\\n\" + alternative1).sum()\n","    lprob2 = get_logprobs(prompt + \"\\n\" + alternative2).sum()\n","    return 1 if lprob1 > lprob2 else 2\n","\n","results_xstory = {\"idx\": list(range(len(x_story_cloze[lang][\"eval\"]))), \n","           \"label\": x_story_cloze[\"en\"][\"eval\"][\"answer_right_ending\"]}\n","for lang in langs_xstory:\n","    predictions = []\n","    id = []\n","    for idx, example in tqdm(enumerate(x_story_cloze[lang][\"eval\"])):\n","        input_sentences = example[\"input_sentence_1\"] + \" \" + example[\"input_sentence_2\"] + \" \" + example[\"input_sentence_3\"] + \" \" + example[\"input_sentence_4\"]\n","        predict = XStoryCloze_eval(input_sentences, example[\"sentence_quiz1\"], example[\"sentence_quiz2\"])\n","        predictions.append(predict)\n","    results_xstory[lang] = predictions"],"metadata":{"id":"YFCbVQAEz6sh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_xstory_df = pd.DataFrame(results_xstory).to_csv(\"XStoryCloze_xglm-564M.tsv\", sep=\"\\t\", index=False)"],"metadata":{"id":"Ct1emCKnEJT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_xstory_df = pd.read_csv(\"XStoryCloze_xglm-564M.tsv\", delimiter=\"\\t\")"],"metadata":{"id":"drNM3tU1HdGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy = {}\n","for lang in langs_xstory:\n","    compare = results_xstory_df[\"label\"] == results_xstory_df[lang]\n","    acc = list(compare).count(True) / len(list(compare)) * 100\n","    accuracy[lang] = round(acc, 1)\n","\n","accuracy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-dtr45xIjLe","executionInfo":{"status":"ok","timestamp":1674658422972,"user_tz":-60,"elapsed":11,"user":{"displayName":"Julen Etxaniz Aragoneses","userId":"06956422670240182492"}},"outputId":"7900e037-f80a-4404-ae2d-d563a3350fb3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'en': 60.0,\n"," 'ru': 55.9,\n"," 'zh': 53.1,\n"," 'es': 54.3,\n"," 'ar': 49.6,\n"," 'hi': 52.2,\n"," 'id': 54.1,\n"," 'te': 55.9,\n"," 'sw': 53.3,\n"," 'eu': 53.1,\n"," 'my': 51.6}"]},"metadata":{},"execution_count":63}]}]}